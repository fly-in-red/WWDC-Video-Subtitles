
1
00:00:07,174 --> 00:00:15,782
(音楽)

2
00:00:21,288 --> 00:00:27,194
(拍手)

3
00:00:27,294 --> 00:00:30,764
おはようございます
マイケルです

4
00:00:31,064 --> 00:00:34,168
新しいCore MLの
セッションです

5
00:00:35,602 --> 00:00:40,741
昨年のCore MLは機械学習モデルの
アプリケーションへの導入を―

6
00:00:40,841 --> 00:00:44,311
驚くほど簡単なものにしました

7
00:00:45,412 --> 00:00:48,916
使っていただいているようで
うれしいです

8
00:00:49,850 --> 00:00:55,322
もしアプリケーションに
新たな能力が備われば―

9
00:00:55,589 --> 00:00:58,358
とてもすばらしいでしょう

10
00:00:59,026 --> 00:01:01,094
例えば画像の理解

11
00:00:59,026 --> 00:01:01,094
例えば画像の理解

12
00:01:02,696 --> 00:01:06,500
もしくはテキストの
分析などができたら？

13
00:01:08,702 --> 00:01:13,874
あなたのアプリケーションが
音声や音楽の認識や

14
00:01:15,342 --> 00:01:18,679
動作認識が
できたらどうでしょう

15
00:01:19,980 --> 00:01:23,283
さらにコンテンツの
変換や作成ができたら？

16
00:01:24,384 --> 00:01:28,755
以上の機能は
とても簡単に手に入ります

17
00:01:29,089 --> 00:01:33,727
Core MLモデルに
コード化できるからです

18
00:01:35,128 --> 00:01:37,464
中をのぞいてみましょう

19
00:01:38,098 --> 00:01:42,903
ニューラルネットワークや
ツリーアンサンブルがあります

20
00:01:43,670 --> 00:01:49,209
ここには大量のデータから得た
パラメータが存在します

21
00:01:50,544 --> 00:01:53,780
しかし注目するのは
１つのファイルです

22
00:01:54,381 --> 00:01:57,284
実装の詳細より
その機能や―

23
00:01:57,384 --> 00:02:01,755
実現している体験に
注目してください

24
00:01:57,384 --> 00:02:01,755
実現している体験に
注目してください

25
00:02:04,791 --> 00:02:10,030
Core MLモデルの追加は
Xcodeにファイルを加えるだけ

26
00:02:11,198 --> 00:02:13,066
シンプルなビューが
出てきます

27
00:02:13,667 --> 00:02:17,204
実現したい動作の設定のため
必要な入力と―

28
00:02:17,304 --> 00:02:19,173
提供される出力を指定します

29
00:02:20,107 --> 00:02:23,844
次に進むとインターフェイスの
生成ができます

30
00:02:24,811 --> 00:02:27,915
数行のコードで
このモデルが作用します

31
00:02:28,815 --> 00:02:32,853
１行目ではモデルのロード
２行目では予測を指示しています

32
00:02:33,687 --> 00:02:36,890
時には ３行目にあるように
特定の出力を指定します

33
00:02:38,091 --> 00:02:40,694
コードのライトバックが
不要なことも

34
00:02:40,794 --> 00:02:43,764
Core MLが高度なAPIに
統合されているからです

35
00:02:43,864 --> 00:02:47,668
Core MLモデルの提供で
カスタマイズも可能です

36
00:02:48,068 --> 00:02:51,872
Visionでは
VNCoreMLRequestを介します

37
00:02:51,972 --> 00:02:53,507
新しいNatural Languageでは

38
00:02:53,607 --> 00:02:56,944
Core MLモデルからNLModelの
インスタンスが生成できます

39
00:02:59,513 --> 00:03:01,114
以上がCore MLの概要です

40
00:02:59,513 --> 00:03:01,114
以上がCore MLの概要です

41
00:03:01,648 --> 00:03:03,517
これから
新機能について話します

42
00:03:04,284 --> 00:03:07,754
この１年で多くの
フィードバックを得て

43
00:03:07,855 --> 00:03:11,458
Core ML 2の
機能強化をしました

44
00:03:12,626 --> 00:03:15,295
２回に分けて話をします

45
00:03:15,696 --> 00:03:21,201
最初のセッションでは
Appに関する新機能について

46
00:03:21,702 --> 00:03:26,940
10時から予定している
２つ目のセッションでは―

47
00:03:27,441 --> 00:03:29,042
ツールについて話します

48
00:03:29,343 --> 00:03:34,014
Core ML 2を活用するための
更新や変換方法も紹介します

49
00:03:36,917 --> 00:03:40,354
App関連の新機能では
３つに焦点を当てます

50
00:03:40,721 --> 00:03:44,925
１つ目は
同じ機能を維持しつつ―

51
00:03:45,025 --> 00:03:47,995
モデルのサイズと数を
減らす方法

52
00:03:48,829 --> 00:03:52,866
２つ目は 単一モデルから
多くのパフォーマンスを得る方法

53
00:03:54,101 --> 00:03:58,939
３つ目は Core MLを使い
急激に進化し続けている―

54
00:03:59,039 --> 00:04:01,675
機械学習分野に
対応する方法です

55
00:03:59,039 --> 00:04:01,675
機械学習分野に
対応する方法です

56
00:04:02,209 --> 00:04:04,478
まずはモデルサイズからです

57
00:04:04,578 --> 00:04:06,246
フランチェスコに代わります

58
00:04:07,014 --> 00:04:10,384
(拍手)

59
00:04:10,484 --> 00:04:11,618
マイケル ありがとう

60
00:04:12,853 --> 00:04:13,420
こんにちは

61
00:04:14,321 --> 00:04:18,291
Core MLのサイズ縮小は
大変重要です

62
00:04:18,625 --> 00:04:22,596
ここで アプリケーションの
サイズ縮小に有益な―

63
00:04:22,930 --> 00:04:26,667
Core ML 2の２つの
新機能を紹介します

64
00:04:28,435 --> 00:04:32,239
Core MLは機能学習モデルを
デバイス上で実行させます

65
00:04:33,640 --> 00:04:37,444
クラウド上での実行と比べて
４つの利点があります

66
00:04:37,744 --> 00:04:40,848
第１にプライバシーの尊重

67
00:04:41,081 --> 00:04:43,584
デバイス上で
機械学習モデルを実行するため

68
00:04:43,851 --> 00:04:47,154
データがデバイス外に
流出することはありません

69
00:04:47,988 --> 00:04:50,991
第２にリアルタイムでの
パフォーマンスの実現

70
00:04:51,992 --> 00:04:56,396
ハードウェアやデバイスは
機械学習に対し超効率的です

71
00:04:57,064 --> 00:05:00,767
サーバの保守や
支払いも必要ありません

72
00:04:57,064 --> 00:05:00,767
サーバの保守や
支払いも必要ありません

73
00:05:01,335 --> 00:05:05,239
Core MLの推論が
いつでも どこでも可能です

74
00:05:05,506 --> 00:05:07,474
ネット接続環境に
左右されません

75
00:05:07,975 --> 00:05:09,943
これらのメリットを得るには

76
00:05:10,043 --> 00:05:13,480
機械学習モデルの
デバイスへの保存が必要です

77
00:05:14,014 --> 00:05:19,119
モデルのサイズが大きいと
Appのサイズも大きくなります

78
00:05:19,753 --> 00:05:24,324
例えば機能が充実した
すばらしいAppがあるとします

79
00:05:24,424 --> 00:05:26,693
ユーザの満足度も高い

80
00:05:26,860 --> 00:05:30,597
そこで デバイス上の
機械学習を利用し

81
00:05:30,697 --> 00:05:34,735
すばらしい機能を
加えることにします

82
00:05:34,902 --> 00:05:39,106
そのために
Core MLモデルに学習させます

83
00:05:39,773 --> 00:05:44,311
ユーザはさらに満足し
幸せを感じるでしょう

84
00:05:45,078 --> 00:05:49,616
ただアプリケーションのサイズは
増加してしまいます

85
00:05:49,950 --> 00:05:52,119
機械学習機能の追加により

86
00:05:52,219 --> 00:05:56,390
数十から数百メガバイト
増えることもあります

87
00:05:57,524 --> 00:06:00,260
さらに新機能を追加すれば

88
00:05:57,524 --> 00:06:00,260
さらに新機能を追加すれば

89
00:06:00,928 --> 00:06:03,697
サイズの増加は止まりません

90
00:06:04,631 --> 00:06:06,833
できることがあります

91
00:06:06,934 --> 00:06:11,205
機械学習モデルが
他の機能をサポートできれば

92
00:06:11,638 --> 00:06:14,341
それをバンドル外に保てます

93
00:06:15,275 --> 00:06:21,315
ユーザは必要時にダウンロードし
デバイス上でコンパイルできます

94
00:06:21,715 --> 00:06:27,120
この場合 サイズ変更はなく
最初は問題ありません

95
00:06:27,221 --> 00:06:31,358
ただ ダウンロード後に
すべての機能を使うと

96
00:06:32,059 --> 00:06:35,529
最終的にアプリケーションの
サイズは増えます

97
00:06:36,196 --> 00:06:38,866
もしモデル自体のサイズを―

98
00:06:40,000 --> 00:06:45,005
小さくすれば
問題は解決するのでしょうか？

99
00:06:46,306 --> 00:06:50,344
App内にそのモデルを含めれば
バンドルが小さくなります

100
00:06:51,378 --> 00:06:56,483
小さいモデルを含めることで
スムーズなダウンロードが可能です

101
00:06:57,084 --> 00:07:00,521
Appのメモリ使用量は
少なくなります

102
00:06:57,084 --> 00:07:00,521
Appのメモリ使用量は
少なくなります

103
00:07:00,888 --> 00:07:05,759
メモリの節約は 一般的に
Appとシステムに好都合です

104
00:07:06,894 --> 00:07:12,299
Core MLのサイズ問題に
どう取り組むかを見ましょう

105
00:07:13,400 --> 00:07:14,801
まずはモデルの数

106
00:07:14,902 --> 00:07:18,939
これは
機械学習機能の数によります

107
00:07:19,273 --> 00:07:21,041
そしてウェイトの数

108
00:07:21,441 --> 00:07:26,146
ウェイトの数は選択した
アーキテクチャにより異なります

109
00:07:26,513 --> 00:07:28,115
マイケルの言及どおり

110
00:07:28,882 --> 00:07:32,619
ウェイトとは機械学習モデルが

111
00:07:32,719 --> 00:07:35,989
習得した情報を記憶する場所です

112
00:07:36,290 --> 00:07:39,860
複雑なタスクの実行を
習得すれば

113
00:07:39,960 --> 00:07:44,164
何千万ものウェイトに
なることもあります

114
00:07:45,532 --> 00:07:47,334
最後はウェイトのサイズ

115
00:07:47,434 --> 00:07:51,004
習得中のパラメータの
格納方法は？

116
00:07:51,805 --> 00:07:53,540
ここは注目点です

117
00:07:54,408 --> 00:07:58,445
ニューラルネットワークには
いくつかの方法があります

118
00:07:59,746 --> 00:08:02,950
iOS 11のCore MLの場合は

119
00:07:59,746 --> 00:08:02,950
iOS 11のCore MLの場合は

120
00:08:03,450 --> 00:08:08,288
浮動小数点数を用い
32ビットで格納されていました

121
00:08:09,923 --> 00:08:11,625
iOS 11.2では

122
00:08:11,959 --> 00:08:16,463
フィードバックをもとに
16ビットになりました

123
00:08:16,697 --> 00:08:22,002
同じ精度で必要なストレージは
半分になりました

124
00:08:22,202 --> 00:08:25,305
今年 新たに導入を試みたのは

125
00:08:25,572 --> 00:08:27,841
量子化されたウェイトです

126
00:08:28,542 --> 00:08:33,947
量子化の末に
32や16という制限はなくなりました

127
00:08:34,114 --> 00:08:38,318
ニューラルネットワークは
８ビットや４ビットも可能で

128
00:08:38,519 --> 00:08:41,121
１ビットまで下げられます

129
00:08:42,155 --> 00:08:45,626
それでは量子化を見ましょう

130
00:08:46,293 --> 00:08:50,330
ニューラルネットワークに
ウェイトのサブセットがあります

131
00:08:50,531 --> 00:08:55,002
ウェイトは連続した範囲で
任意の値を取ります

132
00:08:55,536 --> 00:09:00,941
単一のウェイトが
無限の可能値を取れるのです

133
00:08:55,536 --> 00:09:00,941
単一のウェイトが
無限の可能値を取れるのです

134
00:09:01,041 --> 00:09:03,143
実際にニューラルネットワークでは

135
00:09:03,243 --> 00:09:07,948
32ビットフロートを使って
ウェイトを格納しています

136
00:09:08,081 --> 00:09:10,784
つまり 連続性を表すために

137
00:09:10,884 --> 00:09:14,388
ウェイトは
数十億の値を取るのです

138
00:09:14,555 --> 00:09:19,193
ただしニューラルネットワークは
低精度のウェイトでも作動します

139
00:09:19,893 --> 00:09:24,264
量子化は一連の値を中断する
プロセスであり

140
00:09:24,464 --> 00:09:28,702
可能値のサブセットが
小さく離散するよう―

141
00:09:29,436 --> 00:09:30,904
制御します

142
00:09:31,171 --> 00:09:35,442
例えばこの量子化は
連続するウェイトを―

143
00:09:36,310 --> 00:09:39,379
たった256の可能値に変えました

144
00:09:39,479 --> 00:09:43,183
どんな可能値でも
取得可能だったのが

145
00:09:43,283 --> 00:09:47,254
量子化後のオプションは
たった256です

146
00:09:47,955 --> 00:09:52,192
このようにウェイトの
軽量化が図れたので

147
00:09:52,593 --> 00:09:56,029
Core MLに必要な情報は
たった８ビットです

148
00:09:56,864 --> 00:10:00,200
ここで止まらず さらに進みます

149
00:09:56,864 --> 00:10:00,200
ここで止まらず さらに進みます

150
00:10:00,767 --> 00:10:04,104
ネットワークに対し
256のオプションではなく

151
00:10:04,204 --> 00:10:08,375
８個しか与えない
制御を加えられます

152
00:10:09,576 --> 00:10:15,148
８個のオプションに対して
各ウェイトが必要なのは―

153
00:10:15,415 --> 00:10:16,683
３ビットです

154
00:10:17,551 --> 00:10:22,656
ウェイトを示すための
値の選択方法をお見せします

155
00:10:22,756 --> 00:10:26,026
値は範囲内で
均一に分布していれば

156
00:10:26,126 --> 00:10:31,765
直線量子化ですが
ルックアップテーブル量子化では

157
00:10:33,367 --> 00:10:37,538
任意の方法で
値を分散させられます

158
00:10:37,738 --> 00:10:42,276
量子化がサイズ縮小に
役立つ様子を見ましょう

159
00:10:42,376 --> 00:10:45,112
Resnet50に注目しましょう

160
00:10:45,212 --> 00:10:49,216
様々なタスクに使用される
アーキテクチャです

161
00:10:50,017 --> 00:10:53,187
2500万のパラメータを含んでいます

162
00:10:53,620 --> 00:10:57,257
表示に必要なのは
32ビットフロート

163
00:10:57,925 --> 00:11:00,928
モデルの総サイズは
100メガバイトを超えます

164
00:10:57,925 --> 00:11:00,928
モデルの総サイズは
100メガバイトを超えます

165
00:11:02,396 --> 00:11:06,133
８ビットに量子化しても
アーキテクチャは変わらず

166
00:11:06,233 --> 00:11:09,536
2500万のパラメータは
残りますが

167
00:11:09,636 --> 00:11:13,974
１ウェイトに必要なのは
１バイトのみです

168
00:11:14,074 --> 00:11:17,244
モデルのサイズは４分の１に
なりました

169
00:11:17,344 --> 00:11:20,747
格納に必要なのは
たった26メガバイトです

170
00:11:20,948 --> 00:11:27,020
さらに進んで各ウェイトに
必要なのは４ビットとなり

171
00:11:27,354 --> 00:11:29,223
縮小が実現しています

172
00:11:30,457 --> 00:11:36,430
(拍手)

173
00:11:36,530 --> 00:11:42,769
Core MLでは量子化モードを
８ビットまでサポートしています

174
00:11:44,271 --> 00:11:47,941
量子化は
アーキテクチャ縮小のための―

175
00:11:48,041 --> 00:11:51,211
優れた技術と言えるでしょう

176
00:11:51,378 --> 00:11:53,313
それを手に入れるには？

177
00:11:54,781 --> 00:12:01,555
Core MLフォーマットの場合は
Core ML Toolsを使いますが

178
00:11:54,781 --> 00:12:01,555
Core MLフォーマットの場合は
Core ML Toolsを使いますが

179
00:12:01,655 --> 00:12:04,591
Core ML 2の場合は自動です

180
00:12:05,492 --> 00:12:08,195
量子化モデルの学習も可能です

181
00:12:09,263 --> 00:12:12,599
ゼロから量子化を学習させるか

182
00:12:12,699 --> 00:12:15,802
既存モデルの再学習が可能です

183
00:12:16,403 --> 00:12:21,909
量子化モデルの取得後に
Core MLに変換させます

184
00:12:22,209 --> 00:12:25,345
アプリケーションへの
変更はありません

185
00:12:25,579 --> 00:12:29,483
モデル内の値は
異なる精度ですが

186
00:12:29,583 --> 00:12:33,353
インターフェイスは
全く変更されません

187
00:12:35,522 --> 00:12:38,792
ただし 量子化モデルは―

188
00:12:38,992 --> 00:12:43,764
元の浮動小数点モデルにある
低精度の近似値を含みます

189
00:12:44,231 --> 00:12:49,136
つまり正確性とモデルサイズの
トレードオフがあるのです

190
00:12:49,703 --> 00:12:53,407
このトレードオフはモデルや
ユースケースに依存します

191
00:12:53,774 --> 00:12:56,243
研究が活発な分野なので―

192
00:12:56,443 --> 00:12:59,947
常に量子化モデルの
精度をチェックし

193
00:13:00,047 --> 00:13:03,684
浮動小数点バージョンと比較し

194
00:13:04,017 --> 00:13:08,155
適切なデータかどうか
確認すべきでしょう

195
00:13:08,922 --> 00:13:15,262
では実際に量子化モデルの
使用法をデモで見てみましょう

196
00:13:15,362 --> 00:13:19,233
(拍手)

197
00:13:25,205 --> 00:13:27,541
スタイル変換の
アプリケーションです

198
00:13:28,075 --> 00:13:33,447
ニューラルネットワークは
学習済みのスタイルを用いて

199
00:13:33,547 --> 00:13:36,416
ユーザ画像のレンダリングを
学習します

200
00:13:36,650 --> 00:13:38,051
私のアプリケーションです

201
00:13:39,219 --> 00:13:42,589
４つのスタイルを使います

202
00:13:42,689 --> 00:13:45,559
シティ ガラス 油絵 波

203
00:13:45,659 --> 00:13:49,797
そしてライブラリから
画像を選びます

204
00:13:49,897 --> 00:13:53,700
そしてデバイス上で
スタイルを変えます

205
00:13:53,934 --> 00:13:58,172
この元画像を
シティスタイルで描写

206
00:13:59,940 --> 00:14:00,807
ガラス

207
00:13:59,940 --> 00:14:00,807
ガラス

208
00:14:02,309 --> 00:14:03,210
油絵

209
00:14:04,845 --> 00:14:05,946
そして波

210
00:14:07,414 --> 00:14:09,917
Xcodeを見てみましょう

211
00:14:10,984 --> 00:14:15,722
Core MLとVision APIを
使用しています

212
00:14:16,190 --> 00:14:20,260
Xcodeには４つのCore MLモデルが
バンドルされています

213
00:14:20,360 --> 00:14:23,864
先ほどの
シティ ガラス 油絵 波です

214
00:14:24,464 --> 00:14:26,667
ここで確認ができますが

215
00:14:26,767 --> 00:14:32,306
これらは量子化モデルのため
それぞれ6.7メガバイトです

216
00:14:33,040 --> 00:14:36,343
ある解像度の
入力画像を取り込み

217
00:14:36,577 --> 00:14:40,047
同じ解像度の図案化した画像を
生成するのです

218
00:14:40,981 --> 00:14:42,850
ここで調べたいのは

219
00:14:42,950 --> 00:14:48,489
量子化への切り替えで節約できた
ストレージとメモリスペースです

220
00:14:48,589 --> 00:14:51,425
Core ML Toolsを使いましょう

221
00:14:51,525 --> 00:14:55,729
これらのモデルの
量子化表現を取得しました

222
00:14:56,196 --> 00:14:58,899
モデル入手のための
チュートリアルは

223
00:14:58,999 --> 00:15:03,637
パート２でCore ML Toolsの
詳細を説明します

224
00:14:58,999 --> 00:15:03,637
パート２でCore ML Toolsの
詳細を説明します

225
00:15:04,071 --> 00:15:06,807
ガラススタイルを見ましょう

226
00:15:06,907 --> 00:15:11,211
量子化バージョンの
違いをご覧ください

227
00:15:11,778 --> 00:15:16,083
新しいモデルを
Xcode内にドラッグするだけです

228
00:15:17,951 --> 00:15:21,188
そしてアプリケーションを
再実行します

229
00:15:22,489 --> 00:15:25,792
サイズが大幅に縮小されていますね

230
00:15:25,893 --> 00:15:31,965
８ビット版は６～７メガバイトから
1.7にダウンしています

231
00:15:33,000 --> 00:15:36,937
(拍手)

232
00:15:37,037 --> 00:15:41,675
さらに４ビット版は
１メガバイト未満になりました

233
00:15:41,909 --> 00:15:46,246
３ビット版は49キロバイトしか
ありません

234
00:15:47,114 --> 00:15:49,149
アプリケーションに戻って―

235
00:15:51,151 --> 00:15:56,590
元のバージョンに
ガラスを適用してみましょう

236
00:15:57,257 --> 00:16:02,062
同じに見えますが
ここで８ビット版と比べても

237
00:15:57,257 --> 00:16:02,062
同じに見えますが
ここで８ビット版と比べても

238
00:16:04,364 --> 00:16:06,567
変わりはありません

239
00:16:06,800 --> 00:16:09,903
量子化メソッドが安定しています

240
00:16:10,804 --> 00:16:15,676
さらに挑戦して
４ビット版を試しましょう

241
00:16:16,944 --> 00:16:18,979
すばらしいですね

242
00:16:20,180 --> 00:16:22,182
３ビット版を試すと

243
00:16:24,852 --> 00:16:27,588
ここで色が変わりましたね

244
00:16:27,688 --> 00:16:32,926
許容範囲はデザイナーと
確認するべきでしょう

245
00:16:33,260 --> 00:16:37,865
２ビット版になると
期待どおりにはいきません

246
00:16:37,965 --> 00:16:41,735
ホラー系に取っておき
デザイナーには見せません

247
00:16:41,835 --> 00:16:46,406
(拍手)

248
00:16:46,507 --> 00:16:48,942
４ビット版に戻りましょう

249
00:16:49,143 --> 00:16:54,748
量子化モデルは元の近似値だと
思い出してください

250
00:16:55,148 --> 00:16:58,986
常に元のバージョンとの比較を
お勧めします

251
00:16:59,086 --> 00:17:04,691
モデルと量子化技術において
ミスマッチがあるはずです

252
00:16:59,086 --> 00:17:04,691
モデルと量子化技術において
ミスマッチがあるはずです

253
00:17:06,492 --> 00:17:10,597
デザイナーとの議論を経て
画像を評価し

254
00:17:10,696 --> 00:17:15,903
最小サイズで最良の
４ビットサイズに決めました

255
00:17:16,970 --> 00:17:22,675
他の浮動小数点バージョンを
削除してしまいましょう

256
00:17:23,477 --> 00:17:26,380
そして４ビットに変えます

257
00:17:31,018 --> 00:17:33,420
最後にアプリケーションを実行

258
00:17:40,527 --> 00:17:42,529
同じ画像を選びます

259
00:17:45,165 --> 00:17:46,733
スタイルを変更します

260
00:17:48,702 --> 00:17:50,037
これがシティ

261
00:17:50,871 --> 00:17:51,705
ガラス

262
00:17:53,807 --> 00:17:54,775
油絵

263
00:17:56,376 --> 00:17:57,478
そして波

264
00:18:00,214 --> 00:18:03,684
このデモでは４つのモデルが
ありました

265
00:18:04,051 --> 00:18:09,156
巨大な32ビット版では
アプリケーションは27メガバイト

266
00:18:09,389 --> 00:18:12,893
４ビットに切り替えました

267
00:18:12,993 --> 00:18:16,897
サイズは3.4メガバイトにまで縮小

268
00:18:17,598 --> 00:18:18,365
そして…

269
00:18:18,465 --> 00:18:23,003
(拍手)

270
00:18:23,103 --> 00:18:26,039
犠牲を払わず
品質を保ちました

271
00:18:26,173 --> 00:18:32,412
すべての量子化バージョンは
すばらしいクオリティです

272
00:18:34,481 --> 00:18:37,818
量子化は細かなレベルで
ウェイトや―

273
00:18:37,918 --> 00:18:41,421
アプリケーションの
サイズ縮小に役立ちます

274
00:18:42,189 --> 00:18:46,493
次はアプリケーションが必要な
モデル数を減らす方法です

275
00:18:47,794 --> 00:18:49,797
最も単純なケースでは

276
00:18:50,097 --> 00:18:55,936
３つの機械学習機能には
３つの機械学習モデルが必要です

277
00:18:56,136 --> 00:19:01,308
しかし場合により
異なる機能をサポートするための

278
00:18:56,136 --> 00:19:01,308
しかし場合により
異なる機能をサポートするための

279
00:19:01,408 --> 00:19:03,977
同一モデルも存在します

280
00:19:04,344 --> 00:19:07,347
マルチタスクモデルに
学習させて

281
00:19:07,614 --> 00:19:12,052
同時にマルチタスクを
実行させることも可能です

282
00:19:12,419 --> 00:19:16,690
これはTuri Createのセッションで
用いたサンプルです

283
00:19:16,924 --> 00:19:21,061
場合によりCore MLの新機能も
使用可能です

284
00:19:21,161 --> 00:19:23,497
“柔軟なシェイプとサイズ”です

285
00:19:24,364 --> 00:19:28,068
スタイル変換のデモに戻りましょう

286
00:19:28,168 --> 00:19:32,739
Xcodeでは入力画像と
出力画像のサイズが

287
00:19:32,839 --> 00:19:36,376
モデルの定義の一部で
コード化されています

288
00:19:36,810 --> 00:19:40,614
異なる解像度で
同じスタイルを実行したければ？

289
00:19:41,014 --> 00:19:45,719
同じネットワークを
異なるサイズで実行したい時は？

290
00:19:46,787 --> 00:19:51,592
例えばユーザは 高画質の
スタイル変換を望んで

291
00:19:51,792 --> 00:19:55,362
高解像度の画像を使うでしょう

292
00:19:55,662 --> 00:19:59,633
低解像度の画像しか
入力として指定できない場合

293
00:20:00,000 --> 00:20:04,705
デベロッパとしては
解像度を落として取り込んだ後―

294
00:20:04,805 --> 00:20:07,474
再び解像度を
上げるしかありません

295
00:20:07,741 --> 00:20:10,611
ユーザは感心しないでしょう

296
00:20:11,778 --> 00:20:13,180
従来のモデルでも

297
00:20:14,014 --> 00:20:19,052
Core ML Toolsを使い
高解像度の画像を

298
00:20:19,486 --> 00:20:22,222
取り込むことができました

299
00:20:23,290 --> 00:20:25,993
つまり今までも
Core MLモデルに―

300
00:20:26,093 --> 00:20:32,065
高解像度の画像を直接取り込み
処理できていたのです

301
00:20:33,534 --> 00:20:39,606
ユーザは最終的な画像に
多くの処理を追加するため

302
00:20:40,107 --> 00:20:44,912
ズームインした際の画像は
繊細にしたかったのです

303
00:20:46,513 --> 00:20:48,715
ただし今までは―

304
00:20:48,816 --> 00:20:52,953
２つの異なるモデルを作ることで
それを可能にしていました

305
00:20:53,053 --> 00:20:56,256
通常解像度版と
高解像度版です

306
00:20:56,557 --> 00:21:00,327
ネットワークはすべての解像度を
サポートして

307
00:20:56,557 --> 00:21:00,327
ネットワークはすべての解像度を
サポートして

308
00:21:00,427 --> 00:21:04,064
アプリケーションのサイズは
２倍になります

309
00:21:04,498 --> 00:21:07,701
今は柔軟なシェイプを
実現しています

310
00:21:07,801 --> 00:21:10,137
そのシェイプを使うことで

311
00:21:10,237 --> 00:21:14,675
多くの解像度に対応する
単一モデルができました

312
00:21:15,676 --> 00:21:16,543
Xcodeでは…

313
00:21:16,643 --> 00:21:21,248
(拍手)

314
00:21:21,348 --> 00:21:26,787
入力に画像ファイルが
指定されていますが

315
00:21:27,187 --> 00:21:31,925
解像度のサイズを
柔軟に切り替えられるのです

316
00:21:32,025 --> 00:21:35,662
この単純なサンプルに
SDとHDがあります

317
00:21:36,296 --> 00:21:39,099
モデルは１つだけでいいのです

318
00:21:40,400 --> 00:21:42,636
冗長なコードは要りません

319
00:21:43,303 --> 00:21:47,741
SDとHDの切り替えが
高速で実行できます

320
00:21:47,841 --> 00:21:51,345
モデルのリロードが
必要ないためです

321
00:21:52,546 --> 00:21:56,016
柔軟性の指定には
オプションが２つ

322
00:21:57,050 --> 00:21:59,453
次元の範囲を定義し―

323
00:21:59,553 --> 00:22:03,390
最小および最大の
幅と高さを決めます

324
00:21:59,553 --> 00:22:03,390
最小および最大の
幅と高さを決めます

325
00:22:03,624 --> 00:22:06,427
そして任意の値を選択します

326
00:22:07,127 --> 00:22:11,632
すべてのシェイプを
列挙することも可能です

327
00:22:11,732 --> 00:22:17,471
例えばすべてのアスペクト比と
解像度が違うとします

328
00:22:17,571 --> 00:22:20,440
Core MLはそれを予測しています

329
00:22:20,541 --> 00:22:24,511
多くの最適化を
実行する機会があるのです

330
00:22:24,978 --> 00:22:28,048
アプリケーションも小さくなります

331
00:22:29,249 --> 00:22:30,851
柔軟性があるのは？

332
00:22:30,951 --> 00:22:34,788
複数の解像度を
サポートできるのは？

333
00:22:36,256 --> 00:22:38,292
畳み込みの
ニューラルネットワークは

334
00:22:38,392 --> 00:22:42,563
MS転送に使用される
処理タスクであり

335
00:22:42,763 --> 00:22:45,899
画像補正や超解像を処理します

336
00:22:45,999 --> 00:22:48,035
アーキテクチャの処理も可能です

337
00:22:48,435 --> 00:22:53,140
Core ML Toolsが
モデルの機能をチェックします

338
00:22:54,174 --> 00:22:57,744
Core MLユーザは
柔軟なサイズ対応が可能で

339
00:22:57,844 --> 00:23:00,547
ウェイトのサイズは
量子化で縮小可能

340
00:22:57,844 --> 00:23:00,547
ウェイトのサイズは
量子化で縮小可能

341
00:23:00,647 --> 00:23:02,549
しかしウェイトの数は？

342
00:23:03,217 --> 00:23:08,889
Core MLは
様々なアーキテクチャをサポートし

343
00:23:08,989 --> 00:23:14,495
機械学習に適したサイズのモデルを
選択します

344
00:23:14,595 --> 00:23:18,298
Core MLはAppのサイズを

345
00:23:18,398 --> 00:23:21,368
これら３要素を使い
最適化します

346
00:23:21,468 --> 00:23:24,571
いつでも推論は超高性能です

347
00:23:24,738 --> 00:23:27,975
パフォーマンスと
カスタマイズの新機能は―

348
00:23:28,075 --> 00:23:29,710
ビルが説明します

349
00:23:29,810 --> 00:23:30,377
ありがとう

350
00:23:30,477 --> 00:23:36,283
(拍手)

351
00:23:37,985 --> 00:23:38,719
ありがとうございます

352
00:23:39,786 --> 00:23:43,123
Core MLの基本的な
設計原則の１つは

353
00:23:43,223 --> 00:23:46,727
Appに
最高のパフォーマンスを与えること

354
00:23:46,827 --> 00:23:53,934
そのゴールに沿ったCore MLの
新たな機能をご紹介します

355
00:23:54,902 --> 00:23:58,205
先ほどフランチェスコが
使ったサンプルを見てみましょう

356
00:23:58,305 --> 00:24:04,077
App上では 入力された画像を
図案化します

357
00:23:58,305 --> 00:24:04,077
App上では 入力された画像を
図案化します

358
00:24:04,344 --> 00:24:07,314
それを可能にする
重要な要素が２つあります

359
00:24:07,414 --> 00:24:13,253
スタイル適用のためのパラメータを
格納するMLモデルファイル

360
00:24:13,520 --> 00:24:17,157
そしてMLモデルに取り込む
推論エンジンです

361
00:24:17,257 --> 00:24:21,228
それは出力の生成に
必要な計算を実行します

362
00:24:21,895 --> 00:24:25,966
スタイル変換を効率的に行うために
Appleの技術が―

363
00:24:26,066 --> 00:24:28,702
どのように
活用されているのか？

364
00:24:30,137 --> 00:24:36,210
ニューラルネットワークの例で
レイヤと呼ばれる数学的演算です

365
00:24:36,376 --> 00:24:41,882
各レイヤが画像を変換し
図案化して出力します

366
00:24:42,583 --> 00:24:48,789
モデルには変換やスタイルを決める
各レイヤのウェイトが格納されます

367
00:24:49,623 --> 00:24:55,095
Core MLの推論エンジンでは
各レイヤを高度に最適化

368
00:24:55,195 --> 00:24:57,331
GPUではMetalシェーダを使い

369
00:24:57,431 --> 00:25:01,201
CPU上では有能な計算ができる
Accelerateを使います

370
00:24:57,431 --> 00:25:01,201
CPU上では有能な計算ができる
Accelerateを使います

371
00:25:01,301 --> 00:25:05,806
モデル デバイスの状態などを考え
異なる計算を―

372
00:25:05,906 --> 00:25:09,510
異なるハードウェアに送ります

373
00:25:11,178 --> 00:25:14,281
さらにネットワーク内の
レイヤを融合し

374
00:25:14,381 --> 00:25:17,451
必要な計算を少なく抑えます

375
00:25:18,786 --> 00:25:22,089
状況を理解して最適化をするのです

376
00:25:22,189 --> 00:25:26,693
モデルの詳細は
MLModelのファイルに入っています

377
00:25:27,060 --> 00:25:31,432
推論エンジンとデバイスの詳細も
分かっています

378
00:25:32,299 --> 00:25:35,302
我々が必ず最適化をするので

379
00:25:35,402 --> 00:25:38,972
皆さんはユーザだけに
集中してください

380
00:25:40,340 --> 00:25:42,376
作業負荷はどうでしょう？

381
00:25:42,476 --> 00:25:46,513
複数の予測を
行う必要がある場合は？

382
00:25:47,214 --> 00:25:50,851
情報がないと
Core MLは最適化しません

383
00:25:51,452 --> 00:25:57,157
同じ作業量をこなすには
次のようなことが必要でした

384
00:25:57,257 --> 00:26:01,662
既存のCore ML予測APIに
“for”でループを配置

385
00:25:57,257 --> 00:26:01,662
既存のCore ML予測APIに
“for”でループを配置

386
00:26:01,762 --> 00:26:05,432
そして入力をループして
出力を生成します

387
00:26:06,900 --> 00:26:11,572
裏側で何が起こっているか
詳しく見てみましょう

388
00:26:12,172 --> 00:26:15,576
まず各画像の前処理が必要です

389
00:26:15,676 --> 00:26:18,645
GPUへのデータ送信も
もちろん必須です

390
00:26:19,046 --> 00:26:22,916
その後 計算し
出力画像を生成します

391
00:26:23,016 --> 00:26:28,689
そしてGPUからデータを取り出して
Appに返す後処理があります

392
00:26:29,823 --> 00:26:34,728
この画像の改善の鍵は
GPUパイプラインのバブルの除去

393
00:26:35,863 --> 00:26:38,932
パフォーマンス向上に
つながる理由は 主に２つ

394
00:26:39,032 --> 00:26:43,937
まずGPUの待機時間がなくなり
全体の計算時間が短縮

395
00:26:44,037 --> 00:26:47,574
次にGPUは継続して作動するため

396
00:26:47,674 --> 00:26:50,277
高いパフォーマンスを見せ

397
00:26:50,377 --> 00:26:54,681
各出力を
計算する時間を短縮できます

398
00:26:55,616 --> 00:26:59,987
しかしCore MLにはこのような
心配は要りません

399
00:27:00,087 --> 00:27:03,724
実際 皆さんが心配しているのは

400
00:27:03,924 --> 00:27:07,261
処理時間を短くすることです

401
00:27:07,795 --> 00:27:13,400
解決のため 今年は新たに
バッチAPIを紹介します

402
00:27:14,101 --> 00:27:19,540
以前は入力をループし別々に
予測したのが 新APIでは―

403
00:27:20,440 --> 00:27:24,812
１行の予測で
入力の配列を消費し―

404
00:27:24,912 --> 00:27:26,813
出力の配列を生成

405
00:27:26,914 --> 00:27:28,515
残りはCore MLが処理します

406
00:27:28,615 --> 00:27:34,288
(拍手)

407
00:27:34,788 --> 00:27:39,593
では 先ほどのスタイル変換Appを
例に見てみましょう

408
00:27:39,693 --> 00:27:43,831
ライブラリ内の全画像に
画質を適用するため―

409
00:27:43,931 --> 00:27:46,633
それだけに特化した
単純なAppを使います

410
00:27:46,733 --> 00:27:49,203
200枚の画像に適用します

411
00:27:49,303 --> 00:27:51,839
左側を見てください

412
00:27:51,939 --> 00:27:55,843
ループのため
昨年のAPIを実装しています

413
00:27:55,943 --> 00:27:58,445
右側が新しいバッチAPIです

414
00:27:58,545 --> 00:28:01,415
早速 動かしてみましょう

415
00:27:58,545 --> 00:28:01,415
早速 動かしてみましょう

416
00:28:03,817 --> 00:28:05,652
右側は既に処理完了

417
00:28:05,752 --> 00:28:09,356
左側はまだ処理中…
やっと完了です

418
00:28:09,456 --> 00:28:15,162
(拍手)

419
00:28:15,262 --> 00:28:18,999
新しいAPIには
明らかな改善が見られます

420
00:28:19,399 --> 00:28:24,872
その改善はモデルやデバイスなどに
左右されるでしょうが

421
00:28:24,972 --> 00:28:27,274
予測が大量にある場合

422
00:28:27,374 --> 00:28:32,179
新しいAPIを使用し
Core MLに計算させてください

423
00:28:35,682 --> 00:28:39,620
ユーザに役立つ機能が
ない場合は―

424
00:28:39,720 --> 00:28:42,756
世界一高性能でも無意味です

425
00:28:43,624 --> 00:28:46,460
その役立つ機能が何であれ

426
00:28:46,560 --> 00:28:51,832
Core MLを高性能で
簡単なものにしたいです

427
00:28:52,466 --> 00:28:56,437
機械学習の分野は
急速に拡大しています

428
00:28:56,737 --> 00:28:58,071
その速さは？

429
00:28:58,172 --> 00:29:01,241
少し私の話をしましょう

430
00:28:58,172 --> 00:29:01,241
少し私の話をしましょう

431
00:29:02,843 --> 00:29:07,114
機械学習で解答可能な
単純な質問です

432
00:29:07,648 --> 00:29:12,152
私が知りたいのは
ここに馬がいるかどうか

433
00:29:12,586 --> 00:29:16,690
笑いが聞こえるほど
愚かな質問ですね

434
00:29:16,790 --> 00:29:19,760
小さな子供は大好きでしょう

435
00:29:20,094 --> 00:29:22,362
過去に戻りましょう

436
00:29:22,463 --> 00:29:27,401
私が大学院に行き始めた時
考えた問題です

437
00:29:27,501 --> 00:29:29,903
私の洞察はと言うと

438
00:29:30,871 --> 00:29:32,906
“どうかな　難解だ”

439
00:29:33,240 --> 00:29:35,275
“よく分からないよ”

440
00:29:35,876 --> 00:29:40,247
それから私も年を取り
少し賢くなりました

441
00:29:40,347 --> 00:29:42,983
この分野の変化は著しい

442
00:29:43,083 --> 00:29:47,020
ニューラルネットワークにより
新しい結果も出ています

443
00:29:47,721 --> 00:29:49,656
私は見解を変えました

444
00:29:49,756 --> 00:29:53,293
最先端の研究では答えが出ます

445
00:29:53,393 --> 00:29:56,730
コンピュータが
馬の認識技術を持つのです

446
00:29:56,830 --> 00:29:58,098
ワクワクしますね

447
00:29:58,198 --> 00:29:59,733
(笑い声)

448
00:30:00,334 --> 00:30:02,369
さらに時が過ぎて

449
00:30:02,469 --> 00:30:06,073
Appleに勤務し
再び見解が変化しました

450
00:30:06,440 --> 00:30:09,543
今であれば
Create MLを使います

451
00:30:09,643 --> 00:30:12,813
UIは最高で すぐに馬の種類も
判別できるでしょう

452
00:30:13,313 --> 00:30:15,883
機械学習の専門家であれば

453
00:30:15,983 --> 00:30:19,052
“何を言ってるんだ？”と
思うでしょう

454
00:30:19,153 --> 00:30:21,288
“2007年の時点で
この問題を解けたし”

455
00:30:21,388 --> 00:30:24,158
“2012年には
100回は判別できた”とね

456
00:30:24,491 --> 00:30:25,626
それはさておき

457
00:30:25,726 --> 00:30:31,565
長持ちする高品質のソフトウェアを
望むなら 緊張するでしょう

458
00:30:31,665 --> 00:30:35,536
11年後 この問題の
全体像が変わりました

459
00:30:36,203 --> 00:30:40,607
安心のためにCore MLの
機能を見てみましょう

460
00:30:41,575 --> 00:30:46,513
再び 写真に馬がいるか探す
モデルを例にとります

461
00:30:46,613 --> 00:30:49,249
これはニューラルネットワークです

462
00:30:49,716 --> 00:30:54,621
前述のとおり 高度に最適化された
レイヤから成ります

463
00:30:54,721 --> 00:31:00,160
推論エンジンで 各レイヤが
高度に最適化されています

464
00:30:54,721 --> 00:31:00,160
推論エンジンで 各レイヤが
高度に最適化されています

465
00:31:00,894 --> 00:31:04,298
サポートの対象は多く
増えるばかりで

466
00:31:04,398 --> 00:31:06,934
新たな開発に追随します

467
00:31:07,734 --> 00:31:11,071
サポート対象ではない
レイヤがあったら？

468
00:31:12,272 --> 00:31:16,910
過去の選択肢は
“待つ”か“別モデル”でした

469
00:31:17,444 --> 00:31:20,981
でもこれが馬の発見に重要な
レイヤだったら？

470
00:31:21,115 --> 00:31:23,851
これは画期的な機能です

471
00:31:23,951 --> 00:31:25,219
待てますか？

472
00:31:26,820 --> 00:31:29,857
これは大きな
問題かもしれません

473
00:31:31,191 --> 00:31:34,928
そこでニューラルネットワークの
カスタムレイヤを導入

474
00:31:35,095 --> 00:31:37,865
これで レイヤが欠けていても

475
00:31:37,965 --> 00:31:43,637
Core MLモデルの残りと
組み合わせて実装できます

476
00:31:44,004 --> 00:31:47,941
モデル内でカスタムレイヤは
実装クラスの名前を格納

477
00:31:48,041 --> 00:31:50,510
AAPLCustomHorseLayerです

478
00:31:51,111 --> 00:31:55,649
実装クラスは推測エンジンで
欠けている役割を担い

479
00:31:55,883 --> 00:31:57,851
レイヤの構築と同様―

480
00:31:57,951 --> 00:32:03,357
ここの実装は新たなレイヤに
適用されるべきです

481
00:31:57,951 --> 00:32:03,357
ここの実装は新たなレイヤに
適用されるべきです

482
00:32:04,758 --> 00:32:07,561
実行時にアプリケーションに
含めるのです

483
00:32:07,661 --> 00:32:11,999
そして特定のレイヤのパラメータは
残りの情報と一緒に

484
00:32:12,099 --> 00:32:14,434
MLModelにカプセル化されます

485
00:32:15,969 --> 00:32:17,838
カスタムレイヤの実装は単純で

486
00:32:18,138 --> 00:32:20,440
MLCustomLayerを使うだけ

487
00:32:20,541 --> 00:32:25,312
MLModelのデータに基づきレイヤの
初期化メソッドを提供します

488
00:32:26,079 --> 00:32:30,584
レイヤの出力時にスペースを
配分するメソッドも必要です

489
00:32:31,151 --> 00:32:33,220
その計算方法も

490
00:32:35,222 --> 00:32:40,327
パフォーマンスは同じまま
柔軟性を追加できます

491
00:32:40,994 --> 00:32:43,230
プロトコルにはオプションも
用意されています

492
00:32:43,330 --> 00:32:46,300
モデルへの
Metalシェーダの実装です

493
00:32:46,400 --> 00:32:47,901
“レイヤへの”です

494
00:32:48,335 --> 00:32:53,707
これでCore MLの残りの部分と
同じコマンドでコード化できます

495
00:32:53,807 --> 00:32:58,178
エンコーディングやGPUとの連携に
関わるオーバーヘッドもありません

496
00:32:58,545 --> 00:33:03,450
これがないと
他の作業は行われません

497
00:32:58,545 --> 00:33:03,450
これがないと
他の作業は行われません

498
00:33:04,952 --> 00:33:10,057
ニューラルネットワークモデルと
同じようにCore MLも進歩します

499
00:33:10,557 --> 00:33:11,825
しかし限界はあります

500
00:33:12,860 --> 00:33:18,599
カスタムレイヤはMLMultiArrayの
入力と出力のみを取ります

501
00:33:19,032 --> 00:33:21,568
ニューラルネットワークとの
自然な関係ですが

502
00:33:21,668 --> 00:33:25,572
機械学習分野の進歩は
この分野だけに とどまりません

503
00:33:26,640 --> 00:33:32,579
かつてニューラルネットワークは
画像認識の解決策じゃなかった

504
00:33:33,046 --> 00:33:35,549
しかし今や最先端技術です

505
00:33:37,284 --> 00:33:42,823
カスタムレイヤが適合しない
機械学習Appもあるでしょう

506
00:33:43,023 --> 00:33:48,729
機械学習Appは類似空間に
画像を埋め込むことが可能で

507
00:33:48,829 --> 00:33:55,235
最近傍メソッドなどを使えば
似た画像の検索も可能です

508
00:33:56,870 --> 00:34:03,010
モデルで 音声と動作データを
組み合わせることも可能です

509
00:33:56,870 --> 00:34:03,010
モデルで 音声と動作データを
組み合わせることも可能です

510
00:34:04,912 --> 00:34:10,650
全く新しいモデルタイプを使った
斬新な体験も提供できます

511
00:34:11,051 --> 00:34:15,489
Core MLのシンプルさと可搬性が
望まれます

512
00:34:15,589 --> 00:34:19,592
柔軟性も犠牲にする
必要はありません

513
00:34:20,793 --> 00:34:22,795
カスタムモデルの導入です

514
00:34:23,464 --> 00:34:30,036
カスタムモデルを使用して
Core MLにはない機能をカプセル化

515
00:34:30,404 --> 00:34:34,808
カスタムレイヤと同じく
実装クラスの名が格納されます

516
00:34:35,042 --> 00:34:38,978
クラスは一般推論エンジンの
役割を果たします

517
00:34:39,079 --> 00:34:42,983
パラメータは
MLModelに保存されます

518
00:34:43,550 --> 00:34:48,054
モデルはコードとは関係なく
App内のアセットとなります

519
00:34:50,456 --> 00:34:52,760
カスタムモデルの実装も簡単です

520
00:34:52,860 --> 00:34:55,329
MLCustomModelを公開します

521
00:34:55,429 --> 00:34:59,466
MLModelのデータに基づき
初期化メソッドを入力しましょう

522
00:35:00,134 --> 00:35:02,970
次に入力予測の計算用の
メソッドを入れます

523
00:35:03,337 --> 00:35:10,210
特定のモデルで最適化を行う場合
バッチ実装のオプションがあります

524
00:35:10,310 --> 00:35:12,880
または単一の予測を
呼び出します

525
00:35:14,615 --> 00:35:19,419
Appでのカスタマイズモデル使用は
他のCore MLモデルとほぼ同じです

526
00:35:19,586 --> 00:35:24,358
Xcodeではカスタマイズ要素を持つ
モデルには依存関係があり

527
00:35:24,458 --> 00:35:28,228
実装の名称と
簡単な説明を列挙します

528
00:35:28,529 --> 00:35:31,598
すべての準備が整いました

529
00:35:31,698 --> 00:35:36,036
予測APIは 単一の予測でも
バッチでも変わりません

530
00:35:38,172 --> 00:35:42,676
カスタムレイヤとモデルにより
Core MLをより良く利用できます

531
00:35:42,776 --> 00:35:47,814
しかも機械学習の分野に必要な
柔軟性は保持できます

532
00:35:48,582 --> 00:35:50,918
新しいニューラルネットワーク
レイヤは―

533
00:35:51,018 --> 00:35:56,790
カスタムレイヤを使用すると
様々な最適化が利用できます

534
00:35:57,057 --> 00:36:01,461
カスタムモデルは
タイプや機能の柔軟性がある一方

535
00:35:57,057 --> 00:36:01,461
カスタムモデルは
タイプや機能の柔軟性がある一方

536
00:36:01,562 --> 00:36:04,398
多くの実装作業を必要とします

537
00:36:05,866 --> 00:36:10,704
どちらのカスタマイズも
パラメータをカプセル化できます

538
00:36:10,804 --> 00:36:13,407
モデルの可搬性を高め
コードをシンプルに

539
00:36:15,976 --> 00:36:19,913
すばらしい新機能を
紹介しましたので

540
00:36:20,214 --> 00:36:23,617
是非ベータ版を
ダウンロードしてください

541
00:36:27,087 --> 00:36:30,357
Core MLにAppサイズの
縮小機能があり

542
00:36:30,457 --> 00:36:32,326
パフォーマンスの向上や

543
00:36:32,426 --> 00:36:36,029
最新の機械学習との
柔軟性や互換性もあります

544
00:36:36,530 --> 00:36:39,366
モデルサイズを縮小する
量子化の仕組み

545
00:36:39,466 --> 00:36:42,770
新しいバッチAPIの効率的な処理

546
00:36:42,870 --> 00:36:47,774
カスタムレイヤとカスタムモデルの
活用法を紹介しました

547
00:36:48,375 --> 00:36:51,745
Create MLの
新しいツールとの組み合わせで

548
00:36:51,845 --> 00:36:58,185
AppにML対応の機能を追加して
ユーザのサポートができます

549
00:36:59,853 --> 00:37:04,792
休憩後にここで
機能の確認をしてみてください

550
00:36:59,853 --> 00:37:04,792
休憩後にここで
機能の確認をしてみてください

551
00:37:04,892 --> 00:37:08,362
Core ML Toolsの
ソフトウェアを使って

552
00:37:08,462 --> 00:37:13,767
モデルサイズの縮小を
実際にお見せします

553
00:37:13,867 --> 00:37:14,668
ありがとう

554
00:37:14,968 --> 00:37:20,340
(拍手)